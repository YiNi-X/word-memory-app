import streamlit as st
import json
import sqlite3
import random
from datetime import datetime
from openai import OpenAI

# ==========================================
# âš ï¸ 1. API é…ç½®
# ==========================================
KIMI_API_KEY = "sk-tqxUlkDlyX2N2Ka2fJzjv0aDKr5B8hJGVDhFD9N56vGBjlZf" 
BASE_URL = "https://api.moonshot.cn/v1"

# ==========================================
# 2. æ•°æ®åº“é€»è¾‘ (å‡çº§ç‰ˆï¼šæ”¯æŒä¼šè¯ã€æ–‡ç« ä¸é—å¿˜æ›²çº¿)
# ==========================================
DB_NAME = 'neural_vocab_core.db'

def init_db():
    conn = sqlite3.connect(DB_NAME)
    c = conn.cursor()
    
    # è¡¨1ï¼šå­¦ä¹ ä¼šè¯ (LearningSession) - ä½ çš„"ä¸»çº¿ä»»åŠ¡"
    c.execute('''CREATE TABLE IF NOT EXISTS learning_sessions
                 (id INTEGER PRIMARY KEY AUTOINCREMENT,
                  article_english TEXT,
                  article_chinese TEXT,
                  created_at TIMESTAMP)''')
                  
    # è¡¨2ï¼šä¼šè¯å•è¯è¯¦æƒ… (SessionWords) - ä½ çš„"å•è¯æ¡£æ¡ˆ"
    # status å­—æ®µç”¨äºè®°å½•ï¼š'new', 'remembered', 'forgot'
    c.execute('''CREATE TABLE IF NOT EXISTS session_words
                 (id INTEGER PRIMARY KEY AUTOINCREMENT,
                  session_id INTEGER,
                  word TEXT,
                  meaning TEXT,
                  root_explanation TEXT,
                  imagery_desc TEXT,
                  is_core BOOLEAN,
                  status TEXT DEFAULT 'new',
                  FOREIGN KEY(session_id) REFERENCES learning_sessions(id))''')
    conn.commit()
    conn.close()

# [æ ¸å¿ƒé€»è¾‘] è·å–ä¸Šæ¬¡æ ‡è®°ä¸º"å¿˜è®°"çš„å•è¯
def get_forgotten_words():
    conn = sqlite3.connect(DB_NAME)
    c = conn.cursor()
    # æŸ¥æ‰¾æ‰€æœ‰ status ä¸º 'forgot' çš„å•è¯
    c.execute("SELECT word FROM session_words WHERE status = 'forgot'")
    words = [row[0] for row in c.fetchall()]
    conn.close()
    # å»é‡
    return list(set(words))

# [æ ¸å¿ƒé€»è¾‘] ä¿å­˜ä¸€æ¬¡å®Œæ•´çš„å­¦ä¹ ä¼šè¯
def save_study_session(article_data):
    conn = sqlite3.connect(DB_NAME)
    c = conn.cursor()
    try:
        # 1. å­˜æ–‡ç«  (Session)
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        c.execute('''INSERT INTO learning_sessions (article_english, article_chinese, created_at) 
                     VALUES (?, ?, ?)''', 
                     (article_data['article_english'], article_data['article_chinese'], current_time))
        session_id = c.lastrowid
        
        # 2. å­˜å•è¯ (Words)
        for w in article_data['words']:
            c.execute('''INSERT INTO session_words 
                         (session_id, word, meaning, root_explanation, imagery_desc, is_core, status) 
                         VALUES (?, ?, ?, ?, ?, ?, ?)''', 
                         (session_id, w['word'], w['meaning'], w['root'], w['imagery'], w['is_core'], 'new'))
        
        conn.commit()
        return session_id
    except Exception as e:
        st.error(f"DATABASE ERROR: {e}")
        return None
    finally:
        conn.close()

# [æ ¸å¿ƒé€»è¾‘] æ›´æ–°å•è¯çŠ¶æ€ (æ¯”å¦‚æ ‡è®°ä¸º forgot)
def update_word_status(word_text, new_status):
    conn = sqlite3.connect(DB_NAME)
    c = conn.cursor()
    # è¿™é‡Œæˆ‘ä»¬ç®€åŒ–é€»è¾‘ï¼šæ›´æ–°è¯¥å•è¯åœ¨æ‰€æœ‰å†å²è®°å½•ä¸­çš„çŠ¶æ€ï¼Œæˆ–è€…åªæ›´æ–°æœ€è¿‘çš„
    # ä¸ºäº†å®ç°"æ»šé›ªçƒ"ï¼Œæˆ‘ä»¬åªè¦ç¡®ä¿æ•°æ®åº“é‡Œæœ‰è¿™ä¸ªè¯æ ‡è®°ä¸º forgot å³å¯
    c.execute("UPDATE session_words SET status = ? WHERE word = ?", (new_status, word_text))
    conn.commit()
    conn.close()

def get_stats():
    conn = sqlite3.connect(DB_NAME)
    c = conn.cursor()
    c.execute("SELECT count(*) FROM session_words")
    total = c.fetchone()[0]
    c.execute("SELECT count(*) FROM session_words WHERE status='forgot'")
    forgot = c.fetchone()[0]
    conn.close()
    return total, forgot

# åˆå§‹åŒ–æ•°æ®åº“
init_db()

# ==========================================
# 3. é¡µé¢ä¸»é€»è¾‘ & èµ›åšæœ‹å…‹æ ·å¼ (ä¿æŒåŸå‘³)
# ==========================================
st.set_page_config(page_title="NEURAL_VOCAB_CORE", page_icon="ğŸ§ ", layout="wide")

st.markdown("""
<style>
    /* æ ¸å¿ƒèƒŒæ™¯ä¸å­—ä½“ */
    .stApp {
        background-color: #050505;
        background-image: radial-gradient(#111 20%, transparent 20%), radial-gradient(#111 20%, transparent 20%);
        background-size: 20px 20px;
        color: #e0e0e0;
        font-family: 'Courier New', monospace;
    }
    h1, h2, h3 { color: #00f3ff !important; text-shadow: 0 0 10px #00f3ff; }
    
    /* æ–‡ç« é˜…è¯»åŒºæ ·å¼ */
    .article-box {
        background: #0a0a0a;
        border: 1px solid #333;
        border-left: 4px solid #00f3ff;
        padding: 20px;
        border-radius: 5px;
        font-size: 1.1em;
        line-height: 1.6;
    }
    .highlight-word {
        color: #ff00ff;
        font-weight: bold;
        text-shadow: 0 0 5px #ff00ff;
    }
    
    /* æŒ‰é’®ä¸äº¤äº’ */
    div.stButton > button {
        background: transparent;
        border: 1px solid #39ff14;
        color: #39ff14;
        border-radius: 0;
    }
    div.stButton > button:hover {
        background: #39ff14;
        color: #000;
        box-shadow: 0 0 15px #39ff14;
    }
    div.stButton > button[kind="primary"] {
        border-color: #ff00ff;
        color: #ff00ff;
    }
    
    /* çŠ¶æ€æŒ‡ç¤ºå™¨ */
    .status-badge {
        display: inline-block;
        padding: 2px 8px;
        border: 1px solid #555;
        font-size: 0.8em;
        margin-right: 5px;
    }
</style>
""", unsafe_allow_html=True)

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.title("ğŸ§  ç¥ç»ä¸­æ¢")
    total_count, forgot_count = get_stats()
    st.metric("å·²å­˜å‚¨è®°å¿†å•å…ƒ", f"{total_count}")
    st.metric("å¾…ä¿®å¤è®°å¿† (Forgot)", f"{forgot_count}", delta_color="inverse")
    
    st.divider()
    st.markdown("### ğŸ“¥ æ•°æ®æ³¨å…¥")
    user_input = st.text_area("è¾“å…¥æ–°å•è¯:", value="ephemeral, serendipity", height=100)
    
    # [é€»è¾‘ç‚¹ 1] æ£€æŸ¥æ˜¯å¦æœ‰é—å¿˜å•è¯
    forgotten_cache = get_forgotten_words()
    if forgotten_cache:
        st.warning(f"âš ï¸ æ£€æµ‹åˆ° {len(forgotten_cache)} ä¸ªé—å¿˜å•è¯ï¼Œå°†è‡ªåŠ¨åˆå¹¶åˆ°æœ¬æ¬¡è®­ç»ƒã€‚")
        with st.expander("æŸ¥çœ‹é—å¿˜åˆ—è¡¨"):
            st.write(", ".join(forgotten_cache))
            
    start_btn = st.button("ğŸš€ å¯åŠ¨ç¥ç»é“¾æ¥ (Generate)", type="primary")

# --- Prompt å·¥ç¨‹ (æ ¸å¿ƒï¼šè¦æ±‚ AI å†™æ–‡ç« å¹¶è¿”å›ç»“æ„åŒ–æ•°æ®) ---
SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªè‹±è¯­å­¦ä¹ åŠ©æ‰‹ã€‚
ä»»åŠ¡ï¼šæ ¹æ®æä¾›çš„å•è¯åˆ—è¡¨ï¼Œå†™ä¸€ç¯‡ CET-6 éš¾åº¦çš„çŸ­æ–‡ï¼ˆ150è¯å·¦å³ï¼‰ã€‚
è¦æ±‚ï¼š
1. å¿…é¡»åŒ…å«æ‰€æœ‰ç”¨æˆ·æä¾›çš„å•è¯ã€‚
2. æ–‡ç« è¦é€»è¾‘é€šé¡ºï¼Œåˆ†æ®µï¼ˆSectionï¼‰ã€‚
3. è¯·ä¸¥æ ¼è¾“å‡º JSON æ ¼å¼ï¼Œç»“æ„å¦‚ä¸‹ï¼š
{
    "article_english": "åŒ…å«HTMLæ ‡ç­¾çš„æ–‡ç« ï¼Œè¯·å°†ç›®æ ‡å•è¯ç”¨ <span class='highlight-word'>...</span> åŒ…è£¹",
    "article_chinese": "æ–‡ç« çš„ä¸­æ–‡ç¿»è¯‘",
    "words": [
        {
            "word": "å•è¯åŸå½¢",
            "meaning": "ä¸­æ–‡é‡Šä¹‰",
            "root": "è¯æ ¹è¯ç¼€è§£é‡Š",
            "imagery": "è®°å¿†è”æƒ³ç”»é¢æè¿°",
            "is_core": true/false (æ˜¯å¦ä¸ºæ ¸å¿ƒå¸¸ç”¨è¯)
        }
    ]
}
æ³¨æ„ï¼šç›´æ¥è¿”å› JSONï¼Œä¸è¦ Markdown æ ‡è®°ã€‚
"""

# --- ä¸»é€»è¾‘å¤„ç† ---
if start_btn and user_input:
    # [é€»è¾‘ç‚¹ 2] åˆå¹¶å•è¯åˆ—è¡¨ (æ–°è¯ + é—å¿˜è¯)
    final_word_list = list(set([w.strip() for w in user_input.split(',')] + forgotten_cache))
    
    with st.spinner(f"æ­£åœ¨æ„å»ºç¥ç»çªè§¦... (å¤„ç†å•è¯: {len(final_word_list)} ä¸ª)"):
        try:
            client = OpenAI(api_key=KIMI_API_KEY, base_url=BASE_URL)
            response = client.chat.completions.create(
                model="moonshot-v1-8k",
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": f"è¯·ä½¿ç”¨è¿™äº›å•è¯å†™æ–‡ç« : {', '.join(final_word_list)}"}
                ],
                temperature=0.3,
                response_format={"type": "json_object"}
            )
            data = json.loads(response.choices[0].message.content)
            
            # [é€»è¾‘ç‚¹ 3] å­˜å…¥æ•°æ®åº“
            session_id = save_study_session(data)
            
            # å­˜å…¥ Session State ç”¨äºå±•ç¤º
            st.session_state['current_data'] = data
            # é»˜è®¤æŠŠé—å¿˜åˆ—è¡¨é‡Œçš„è¯çŠ¶æ€é‡ç½®ï¼Œå› ä¸ºæˆ‘ä»¬è¿™æ¬¡å­¦äº†
            # (è¿™é‡Œä¸ºäº†ç®€å•ï¼Œå‡è®¾åªè¦ç”Ÿæˆäº†æ–°æ–‡ç« ï¼Œè¿™äº›è¯å°±æš‚æ—¶ç®—"å¤ä¹ è¿‡"ï¼ŒçŠ¶æ€å¯ä»¥æ”¹ä¸º new æˆ– rememberedï¼Œ
            #  æˆ–è€…ç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨æ ‡è®°ã€‚ä¸ºäº†ä½“éªŒé—­ç¯ï¼Œæˆ‘ä»¬å…ˆä¸è‡ªåŠ¨æ”¹ï¼Œè®©ç”¨æˆ·åœ¨ä¸‹é¢æ‰‹åŠ¨ç‚¹ 'è®°ä½äº†')
            
        except Exception as e:
            st.error(f"SYSTEM FAILURE: {e}")

# --- æ¸²æŸ“ç•Œé¢ ---
st.title("âš¡ NEURAL LEARNING FLOW")

if 'current_data' in st.session_state:
    data = st.session_state['current_data']
    
    # Tab åˆ†é¡µï¼šé˜…è¯»æ¨¡å¼ vs è®°å¿†æ¨¡å¼
    tab1, tab2 = st.tabs(["ğŸ“œ æ²‰æµ¸é˜…è¯» (Context)", "ğŸ§© è®°å¿†ç¢ç‰‡ (Details)"])
    
    with tab1:
        col1, col2 = st.columns([1, 1])
        with col1:
            st.markdown("### ENGLISH LAYER")
            # æ¸²æŸ“å¸¦é«˜äº® HTML çš„æ–‡ç« 
            st.markdown(f"<div class='article-box'>{data['article_english']}</div>", unsafe_allow_html=True)
        with col2:
            st.markdown("### CHINESE LAYER")
            st.markdown(f"<div class='article-box' style='color:#aaa; border-left-color:#555;'>{data['article_chinese']}</div>", unsafe_allow_html=True)

    with tab2:
        st.write("ç‚¹å‡» `FORGOT` ä¼šå°†å•è¯åŠ å…¥å¾…å¤ä¹ é˜Ÿåˆ—ï¼Œä¸‹æ¬¡ç”Ÿæˆæ—¶è‡ªåŠ¨å‡ºç°ã€‚")
        # ç½‘æ ¼å¸ƒå±€å±•ç¤ºå•è¯å¡ç‰‡
        cols = st.columns(3)
        for idx, w in enumerate(data['words']):
            with cols[idx % 3]:
                with st.container(border=True):
                    # å•è¯å¤´
                    st.markdown(f"<h3 style='margin:0'>{w['word']}</h3>", unsafe_allow_html=True)
                    if w['is_core']:
                        st.markdown("<span class='status-badge' style='color:#39ff14; border-color:#39ff14'>CORE</span>", unsafe_allow_html=True)
                    st.divider()
                    
                    # è¯¦ç»†ä¿¡æ¯
                    st.markdown(f"**é‡Šä¹‰:** {w['meaning']}")
                    st.markdown(f"**ğŸŒ± è¯æ ¹:** {w['root']}")
                    st.markdown(f"**ğŸ–¼ï¸ ç”»é¢:** *{w['imagery']}*")
                    
                    st.divider()
                    # [é€»è¾‘ç‚¹ 4] äº¤äº’æŒ‰é’®ï¼šé—å¿˜/è®°ä½
                    c1, c2 = st.columns(2)
                    with c1:
                        if st.button("ğŸ”´ FORGOT", key=f"f_{idx}"):
                            update_word_status(w['word'], 'forgot')
                            st.toast(f"å·²æ ‡è®° {w['word']} ä¸ºå¾…å¤ä¹ ", icon="ğŸ§ ")
                    with c2:
                        if st.button("ğŸŸ¢ GOT IT", key=f"r_{idx}"):
                            update_word_status(w['word'], 'remembered')
                            st.toast(f"è®°å¿†å·²å¼ºåŒ–: {w['word']}", icon="âœ…")

else:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾“å…¥å•è¯ï¼Œå¼€å§‹æœ¬æ¬¡ç¥ç»é“¾æ¥ã€‚")
    st.markdown("""
    > **å½“å‰ç³»ç»Ÿç‰¹æ€§:**
    > 1. **è‡ªåŠ¨å›æ»šå¤ä¹ **: å·¦ä¾§ä¼šè‡ªåŠ¨æ£€æµ‹ä½ ä¸Šæ¬¡æ ‡è®°ä¸º `Forgot` çš„å•è¯ã€‚
    > 2. **è¯­å¢ƒç”Ÿæˆ**: ä¸å†æ˜¯å­¤ç«‹çš„å•è¯å¡ï¼Œè€Œæ˜¯ç”Ÿæˆä¸€ç¯‡åŒ…å«æ‰€æœ‰å•è¯çš„**å®Œæ•´æ–‡ç« **ã€‚
    > 3. **è®°å¿†é—­ç¯**: åœ¨å³ä¾§ Tab ä¸­ç‚¹å‡» `FORGOT`ï¼Œè¯¥è¯ä¼šè¿›å…¥"å¾…ä¿®å¤"æ± ï¼Œä¸‹æ¬¡è‡ªåŠ¨åŠ å…¥å­¦ä¹ åˆ—è¡¨ã€‚
    """)