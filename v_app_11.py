import streamlit as st
import json
import sqlite3
import re
from datetime import datetime
from openai import OpenAI

# ==========================================
# 1. API é…ç½®
# ==========================================
KIMI_API_KEY = "sk-tqxUlkDlyX2N2Ka2fJzjv0aDKr5B8hJGVDhFD9N56vGBjlZf"
BASE_URL = "https://api.moonshot.cn/v1"
MODEL_ID = "kimi-k2.5"

# ==========================================
# 2. æ•°æ®åº“é€»è¾‘
# ==========================================
DB_NAME = 'neural_vocab_lazy.db'

def init_db():
    conn = sqlite3.connect(DB_NAME)
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS learning_sessions
                 (id INTEGER PRIMARY KEY AUTOINCREMENT,
                  words_input TEXT,
                  article_english TEXT,
                  article_chinese TEXT,
                  created_at TIMESTAMP)''')
    c.execute('''CREATE TABLE IF NOT EXISTS session_words
                 (id INTEGER PRIMARY KEY AUTOINCREMENT,
                  session_id INTEGER,
                  word TEXT,
                  meaning TEXT,
                  root_explanation TEXT,
                  imagery_desc TEXT,
                  is_core BOOLEAN,
                  status TEXT DEFAULT 'new',
                  FOREIGN KEY(session_id) REFERENCES learning_sessions(id))''')
    conn.commit()
    conn.close()

def create_empty_session(words_str):
    conn = sqlite3.connect(DB_NAME)
    c = conn.cursor()
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    c.execute("INSERT INTO learning_sessions (words_input, created_at) VALUES (?, ?)", (words_str, current_time))
    session_id = c.lastrowid
    conn.commit()
    conn.close()
    return session_id

def update_session_article(session_id, en, cn):
    conn = sqlite3.connect(DB_NAME)
    c = conn.cursor()
    c.execute("UPDATE learning_sessions SET article_english = ?, article_chinese = ? WHERE id = ?", (en, cn, session_id))
    conn.commit()
    conn.close()

def save_words(session_id, words_data):
    conn = sqlite3.connect(DB_NAME)
    c = conn.cursor()
    for w in words_data:
        c.execute('''INSERT INTO session_words 
                     (session_id, word, meaning, root_explanation, imagery_desc, is_core) 
                     VALUES (?, ?, ?, ?, ?, ?)''', 
                     (session_id, w['word'], w['meaning'], w['root'], w['imagery'], w['is_core']))
    conn.commit()
    conn.close()

init_db()

# ==========================================
# 3. AI äº¤äº’æ ¸å¿ƒ
# ==========================================
def get_stream_response(system_prompt, user_content):
    client = OpenAI(api_key=KIMI_API_KEY, base_url=BASE_URL)
    stream = client.chat.completions.create(
        model=MODEL_ID,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_content}
        ],
        temperature=1,
        stream=True,
        response_format={"type": "json_object"}
    )
    return stream

def clean_json_string(s):
    s = re.sub(r'^```json\s*', '', s)
    s = re.sub(r'^```\s*', '', s)
    s = re.sub(r'\s*```$', '', s)
    return s.strip()

PROMPT_ARTICLE = """
ä½ æ˜¯ä¸€ä¸ªè‹±è¯­å°è¯´å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„å•è¯ï¼Œå†™ä¸€ç¯‡ CET-6 éš¾åº¦çš„çŸ­æ–‡ã€‚
è¦æ±‚ï¼š
1. å¿…é¡»åŒ…å«æ‰€æœ‰å•è¯ï¼Œå¹¶ç”¨ <span class='highlight-word'>å•è¯</span> åŒ…è£¹ã€‚
2. è¿”å› JSON: {"article_english": "...", "article_chinese": "..."}
"""

PROMPT_CARDS = """
ä½ æ˜¯ä¸€ä¸ªè¯æºå­¦å®¶ã€‚è¯·åˆ†æç”¨æˆ·æä¾›çš„å•è¯ã€‚
è¦æ±‚ï¼š
1. è§£æè¯æ ¹ã€æä¾›è”æƒ³ç”»é¢ã€åˆ¤æ–­æ˜¯å¦æ ¸å¿ƒè¯ã€‚
2. è¿”å› JSON: 
{
  "words": [
    {"word": "...", "meaning": "...", "root": "...", "imagery": "...", "is_core": true/false}
  ]
}
"""

PROMPT_QUIZ = """
ä½ æ˜¯ä¸€ä¸ªå‡ºé¢˜è€å¸ˆã€‚è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„å•è¯è®¾è®¡ 2 é“å•é¡¹é€‰æ‹©é¢˜ã€‚
è¦æ±‚ï¼š
1. è¿”å› JSON:
{
  "quizzes": [
    {"question": "...", "options": ["A", "B", "C", "D"], "answer": "æ­£ç¡®é€‰é¡¹å†…å®¹", "explanation": "..."}
  ]
}
"""


# ==========================================
# 4. é¡µé¢ UI è®¾ç½®
# ==========================================
st.set_page_config(page_title="NEURAL_MODULAR_SYSTEM_V11", page_icon="âš¡", layout="wide")

st.markdown("""
<style>
    .stApp { background-color: #050505; color: #e0e0e0; font-family: 'Courier New', monospace; }
    /* ğŸ”´ æ”¹äº†è¿™é‡Œï¼šæ ‡é¢˜é¢œè‰²å˜æˆå“çº¢ï¼Œç”¨äºéªŒè¯ä½ çš„æ–‡ä»¶æ˜¯å¦æ›´æ–° */
    h1 { color: #ff00ff !important; text-shadow: 0 0 10px #ff00ff; }
    h2, h3 { color: #00f3ff !important; text-shadow: 0 0 5px #00f3ff; }
    
    .status-box { border: 1px solid #333; padding: 10px; background: #111; margin-bottom: 10px; border-left: 5px solid #00f3ff; }
    .highlight-word { color: #ff00ff; font-weight: bold; text-decoration: underline; }
    div.stButton > button { border: 1px solid #39ff14; color: #39ff14; background: transparent; }
    
    .step-indicator { padding: 5px; margin: 5px 0; border-radius: 4px; font-size: 0.8em; text-align: center; }
    .step-done { background: #004400; color: #39ff14; border: 1px solid #39ff14; }
    .step-active { background: #002244; color: #00f3ff; border: 1px solid #00f3ff; animation: pulse 1.5s infinite; }
    .step-waiting { background: #222; color: #666; border: 1px solid #444; }
    
    @keyframes pulse { 0% { opacity: 0.6; } 50% { opacity: 1; } 100% { opacity: 0.6; } }
</style>
""", unsafe_allow_html=True)

# State åˆå§‹åŒ–
if 'pipeline_status' not in st.session_state: st.session_state['pipeline_status'] = 'idle'
if 'current_words_list' not in st.session_state: st.session_state['current_words_list'] = []
if 'session_id' not in st.session_state: st.session_state['session_id'] = None
if 'data_article' not in st.session_state: st.session_state['data_article'] = None
if 'data_cards' not in st.session_state: st.session_state['data_cards'] = None
if 'data_quiz' not in st.session_state: st.session_state['data_quiz'] = None

# ä¾§è¾¹æ 
with st.sidebar:
    st.title("ğŸ§© æ¨¡å—åŒ–ä¸­æ¢ V11")
    user_input = st.text_area("è¾“å…¥æ•°æ®æµ:", value="ephemeral, serendipity", height=100)
    if st.button("ğŸ“¥ æ³¨å…¥æ•°æ® (Initialize)"):
        words = [w.strip() for w in user_input.split(',') if w.strip()]
        st.session_state['current_words_list'] = words
        st.session_state['pipeline_status'] = 'ready'
        st.session_state['data_article'] = None
        st.session_state['data_cards'] = None
        st.session_state['data_quiz'] = None
        sess_id = create_empty_session(user_input)
        st.session_state['session_id'] = sess_id
        st.success(f"âœ… æ•°æ®å·²æŒ‚è½½! ID: {sess_id}")

# é¡¶æ çŠ¶æ€
st.title("âš¡ NEURAL MODULAR SYSTEM")
status = st.session_state['pipeline_status']

# è¾…åŠ©å‡½æ•°ï¼šè®¡ç®—çŠ¶æ€æ ·å¼
def get_class(target, current):
    order = ['idle', 'ready', 'generating_article', 'generating_cards', 'generating_quiz', 'done']
    try:
        curr_idx = order.index(current)
        target_idx = order.index(target)
        if current == 'done' or curr_idx > target_idx: return "step-done"
        if current == target: return "step-active"
        return "step-waiting"
    except: return "step-waiting"

c1, c2, c3 = st.columns(3)
with c1: st.markdown(f"<div class='step-indicator {get_class('generating_article', status)}'>1. ARTICLE (æ–‡ç« )</div>", unsafe_allow_html=True)
with c2: st.markdown(f"<div class='step-indicator {get_class('generating_cards', status)}'>2. MEMORY (è®°å¿†)</div>", unsafe_allow_html=True)
with c3: st.markdown(f"<div class='step-indicator {get_class('generating_quiz', status)}'>3. COMBAT (æ¼”ç»ƒ)</div>", unsafe_allow_html=True)

st.divider()

if status == 'ready':
    if st.button("ğŸš€ å¯åŠ¨ç¥ç»é“¾è·¯ (START SEQUENCE)", use_container_width=True):
        st.session_state['pipeline_status'] = 'generating_article'
        st.rerun()

# ==========================================
# 5. ç»Ÿä¸€æ¸²æŸ“é€»è¾‘
# ==========================================
tab_article, tab_cards, tab_quiz = st.tabs(["ğŸ“œ é˜…è¯» (READ)", "ğŸ§© è®°å¿† (MEMORY)", "âš”ï¸ æ¼”ç»ƒ (COMBAT)"])

# --- Tab 1: Article ---
with tab_article:
    if status == 'generating_article':
        st.info("âš¡ æ­£åœ¨æ¥æ”¶æ–‡ç« æ•°æ®æµ...")
        stream_box = st.empty()
        full_text = ""
        try:
            stream = get_stream_response(PROMPT_ARTICLE, f"å•è¯: {st.session_state['current_words_list']}")
            for chunk in stream:
                content = chunk.choices[0].delta.content or ""
                full_text += content
                stream_box.code(full_text, language='json')
            
            clean_text = clean_json_string(full_text)
            data = json.loads(clean_text)
            st.session_state['data_article'] = data
            update_session_article(st.session_state['session_id'], data['article_english'], data['article_chinese'])
            
            st.session_state['pipeline_status'] = 'generating_cards'
            st.rerun()
        except Exception as e:
            st.error(f"Error: {e}")

    elif st.session_state['data_article']:
        data = st.session_state['data_article']
        col_en, col_cn = st.columns(2)
        with col_en:
            st.markdown("### English Stream")
            st.markdown(f"{data['article_english']}", unsafe_allow_html=True)
        with col_cn:
            st.markdown("### ä¸­æ–‡è¯‘æ–‡")
            st.markdown(f"<span style='color:#aaa'>{data['article_chinese']}</span>", unsafe_allow_html=True)
            
    else:
        st.markdown("*ç­‰å¾…é“¾è·¯å¯åŠ¨...*")


# --- Tab 2: Cards ---
with tab_cards:
    if status == 'generating_cards':
        st.info("ğŸ§  æ­£åœ¨è§£æè®°å¿†ç¢ç‰‡...")
        stream_box = st.empty()
        full_text = ""
        try:
            stream = get_stream_response(PROMPT_CARDS, f"å•è¯: {st.session_state['current_words_list']}")
            for chunk in stream:
                content = chunk.choices[0].delta.content or ""
                full_text += content
                stream_box.code(full_text, language='json')
            
            clean_text = clean_json_string(full_text)
            data = json.loads(clean_text)
            st.session_state['data_cards'] = data
            save_words(st.session_state['session_id'], data['words'])
            
            st.session_state['pipeline_status'] = 'generating_quiz'
            st.rerun()
        except Exception as e:
            st.error(f"Error: {e}")

    elif st.session_state['data_cards']:
        for w in st.session_state['data_cards']['words']:
            with st.container(border=True):
                st.subheader(w['word'])
                st.markdown(f"**å«ä¹‰:** {w['meaning']} | **è¯æ ¹:** <span style='color:#39ff14'>{w['root']}</span>", unsafe_allow_html=True)
                st.write(f"**ç”»é¢:** {w['imagery']}")
                
    else:
        st.markdown("*ç­‰å¾…æ–‡ç« æ¨¡å—å®Œæˆ...*")


# --- Tab 3: Quiz ---
with tab_quiz:
    if status == 'generating_quiz':
        st.info("âš”ï¸ æ­£åœ¨æ„å»ºæˆ˜åœº...")
        stream_box = st.empty()
        full_text = ""
        try:
            stream = get_stream_response(PROMPT_QUIZ, f"å•è¯: {st.session_state['current_words_list']}")
            for chunk in stream:
                content = chunk.choices[0].delta.content or ""
                full_text += content
                stream_box.code(full_text, language='json')
            
            clean_text = clean_json_string(full_text)
            data = json.loads(clean_text)
            st.session_state['data_quiz'] = data
            
            st.session_state['pipeline_status'] = 'done'
            st.rerun()
        except Exception as e:
            st.error(f"Error: {e}")

    elif st.session_state['data_quiz']:
        for i, q in enumerate(st.session_state['data_quiz']['quizzes']):
            st.markdown(f"**Q{i+1}: {q['question']}**")
            choice = st.radio("é€‰æ‹©:", q['options'], key=f"q_{i}", index=None)
            if choice:
                if choice == q['answer']: st.success("âœ… æ­£ç¡®")
                else: st.error(f"âŒ é”™è¯¯ã€‚ç­”æ¡ˆæ˜¯: {q['answer']}")
                st.caption(f"è§£æ: {q['explanation']}")
            st.divider()
    else:
        st.markdown("*ç­‰å¾…è®°å¿†æ¨¡å—å®Œæˆ...*")